options:
  docker: true

image: node:16-alpine

definitions:
  steps:
    - step: &test
        caches:
          - node
        script:
          - npm install
          - npm test

    - step: &build-staging
        name: Build Docker image
        script:
          - apk add make git
          - make build
          - docker save --output image.cache $(make image_tag)
        artifacts:
          - image.cache

    - step: &push-staging
        name: Push to staging gcr
        script:
          # roles/artifactregistry.writer
          - docker load --input ./image.cache
          - apk add make git
          - echo $GCP_KEY_JSON_STAGING | base64 -d > ./gcloud-api-key.json
          - cat ./gcloud-api-key.json | docker login -u _json_key --password-stdin https://gcr.io
          - make update_latest

    - step: &deploy-staging
        name: Deploy staging
        image: google/cloud-sdk:alpine
        script:
          # roles/container.developer
          - apk add make git
          - IMAGE_REF=$(make image_tag)
          - echo $GCP_KEY_JSON_STAGING | base64 -d > ./gcloud-api-key.json
          - gcloud auth activate-service-account --key-file gcloud-api-key.json
          - gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $GKE_ZONE --project $GKE_PROJECT
          - gcloud components install gke-gcloud-auth-plugin
          - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          - install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          - kubectl set image deployment.v1.apps/dentrino-simulations-api dentrino-simulations-api=$IMAGE_REF -n staging
          ## NOTE(joseb): Once this https://bitbucket.org/atlassian/google-gke-kubectl-run/pull-requests/22 is merged,
          ## we can use pipe.
          # - pipe: atlassian/google-gke-kubectl-run:2.2.0
          #   variables:
          #     KEY_FILE: $GCP_KEY_JSON_STAGING
          #     PROJECT: $GKE_PROJECT
          #     COMPUTE_ZONE: $GKE_ZONE
          #     CLUSTER_NAME: $GKE_CLUSTER_NAME
          #     KUBECTL_COMMAND: 'set image deployment.v1.apps/dentrino-simulations-api'
          #     KUBECTL_ARGS:
          #       - 'dentrino-simulations-api=$IMAGE_REF'
          #       - '-n staging'
          - pipe: atlassian/slack-notify:2.0.0
            variables:
              WEBHOOK_URL: $SLACK_WEBHOOK_URL
              PRETEXT: 'Notification from Dentrino-Simulation-API'
              MESSAGE: 'Staging deployment success! Current image is $IMAGE_REF.'

    - step: &build-prod
        name: Build Docker image
        script:
          - apk add make git
          - export PROJECT_ID=dentrino-production
          - make build
          - docker save --output image.cache $(make image_tag)
        artifacts:
          - image.cache

    - step: &push-prod
        name: Push to prod gcr
        image: google/cloud-sdk:alpine
        script:
          # roles/artifactregistry.writer
          - docker load --input ./image.cache
          - apk add make git
          - echo $GCP_KEY_JSON_PROD | base64 -d > ./gcloud-api-key.json
          - cat ./gcloud-api-key.json | docker login -u _json_key --password-stdin https://gcr.io
          - PROJECT_ID=dentrino-production APP_ENV=production make update_latest

    - step: &deploy-prod
        name: Deploy production
        script:
          - echo "Production deployment is performed by IaC!"

pipelines:
  branches:
    master:
      - step: *test
      - step: *build-prod
      - step: *push-prod
      - step: *deploy-prod
    staging:
      - step: *test
      - step: *build-staging
      - step: *push-staging
      - step: *deploy-staging

  pull-requests:
    '**':
      - step: *test
      - step: *build-staging
